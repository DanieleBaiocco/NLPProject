{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
        "import transformers\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Optimizer\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from abc import ABC, abstractmethod\n",
        "import random\n",
        "from statistics import mode\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "D8DvnzD7DP0M"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mount_directory = \"/content/drive\"\n",
        "dataset_path = os.path.join(mount_directory, 'MyDrive/MELD/MELD_train_efr.json')\n",
        "model_card = 'bert-base-uncased'\n",
        "drive.mount(mount_directory)\n",
        "initial_seed = 2\n",
        "seeds = [42, 53, 146, 34, 21]\n",
        "batch_size = 6\n",
        "patience = 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTPAnY4jWukx",
        "outputId": "bcfafa28-b6ed-4656-e515-04105772ee5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_onehotencoder(data: pd.core.series.Series) -> LabelBinarizer:\n",
        "  onehotencoder = LabelBinarizer()\n",
        "  data_flattened = np.concatenate(data.values)\n",
        "  onehotencoder.fit(data_flattened)\n",
        "  return onehotencoder"
      ],
      "metadata": {
        "id": "ENzi7RazbZeU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sbagliato, deve esserci un tokentypeids per ogni token e deve essere riferito a uno speaker particolare\n",
        "def map_to_order_of_occurrence(data: list) -> list:\n",
        "    # When a new entry is added, its value is computed using the lambda function\n",
        "    dict_order_of_occurrence = defaultdict(lambda: len(dict_order_of_occurrence)+1)\n",
        "    order_of_occurrence = [dict_order_of_occurrence[element] for element in data]\n",
        "    return order_of_occurrence"
      ],
      "metadata": {
        "id": "Pp1Tfr8PAVU8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_none_with_zero(data: list) -> list:\n",
        "    return [0 if x is None else x for x in data]"
      ],
      "metadata": {
        "id": "Qqer3ZIOE-td"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_dialogue(dialogue_text: list, tokenizer,  speakers = None) -> list:\n",
        "    if speakers!=None:\n",
        "      tokenized_dialogue = [[speakers[idx]] + tokenizer.tokenize(utterance) + [tokenizer.sep_token] for idx, utterance in enumerate(dialogue_text)]\n",
        "    else:\n",
        "      tokenized_dialogue = [tokenizer.tokenize(utterance) + [tokenizer.sep_token] for utterance in dialogue_text]\n",
        "    tokenized_dialogue.insert(0, [tokenizer.cls_token])\n",
        "    flattened_tokens = [token for sublist in tokenized_dialogue for token in sublist]\n",
        "    return flattened_tokens"
      ],
      "metadata": {
        "id": "ktvQEsNPE618"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_padding(x: list, max_x_length: int, pad_value, pad_length = None) -> list:\n",
        "    x_length = len(x)\n",
        "    num_pad_values = max_x_length - x_length\n",
        "    if pad_length == None:\n",
        "      padded_x = x + [pad_value] * num_pad_values\n",
        "    else:\n",
        "      pad_list = [pad_value] * pad_length\n",
        "      pad_lists = np.tile(pad_list, (num_pad_values, 1))\n",
        "      padded_x = np.concatenate((x, pad_lists), axis=0)\n",
        "    return padded_x"
      ],
      "metadata": {
        "id": "oA4NVL4vOd6k"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_alternative_dialogue(utterances: pd.core.series.Series, speakers: pd.core.series.Series, tokenizer) -> pd.core.series.Series:\n",
        "  dialogue_column = []\n",
        "  for dialogue_index, dialogue in utterances.items():\n",
        "    dialogue_column.append(tokenize_dialogue(dialogue, tokenizer, speakers[dialogue_index]))\n",
        "  return pd.Series(dialogue_column)"
      ],
      "metadata": {
        "id": "AuDGLC_mioTI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataframes(df, emotions_encoder, tokenizer):\n",
        "    column_names = ['emotions', 'speakers', 'triggers', 'dialogues', 'dialogues_ids', 'attention_masks']\n",
        "    df_standard = pd.DataFrame(columns = column_names)\n",
        "    df_standard['speakers'] = df['speakers'].apply(lambda x: map_to_order_of_occurrence(x))\n",
        "    df_standard['emotions'] = df['emotions'].apply(lambda x: emotions_encoder.transform(x))\n",
        "    df_standard['triggers'] = df['triggers'].apply(lambda x: replace_none_with_zero(x))\n",
        "    df_variation = copy.deepcopy(df_standard)\n",
        "    df_standard['dialogues'] = df['utterances'].apply(lambda x: tokenize_dialogue(x, tokenizer))\n",
        "    df_variation['dialogues'] = build_alternative_dialogue(df['utterances'], df_standard['speakers'], tokenizer)\n",
        "    return df_standard, df_variation"
      ],
      "metadata": {
        "id": "-lTKm0ZnaRzq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_dataframe(df):\n",
        "    _folder = Path.cwd().joinpath(\"dataframes\")\n",
        "    if not _folder.exists():\n",
        "        _folder.mkdir(parents=True)\n",
        "\n",
        "    df_path = Path.joinpath(_folder, 'df_MELD_efr'+'.pkl')\n",
        "    df.to_pickle(df_path)"
      ],
      "metadata": {
        "id": "5g6CwpOlYgGN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataframe():\n",
        "    df_path = 'dataframes/df_MELD_efr.pkl'\n",
        "    if not os.path.exists(df_path):\n",
        "        raise FileNotFoundError(\"{0} dataframe does not exist!\".format(df_path))\n",
        "\n",
        "    with open(df_path, 'rb') as file:\n",
        "        df = pickle.load(file)\n",
        "    return df"
      ],
      "metadata": {
        "id": "6mJwYXvlYlMK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataframe(orginal_df: pd.DataFrame, seed: int):\n",
        "    #train, test_validation = train_test_split(orginal_df, test_size=0.2, random_state=seed)\n",
        "    train, test_validation = train_test_split(orginal_df, test_size=0.2, random_state=seed)\n",
        "    validation, test = train_test_split(test_validation, test_size=0.5, random_state=seed)\n",
        "    return train.reset_index(drop=True), validation.reset_index(drop=True), test.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "keNSPuCNqcWR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, speakers: pd.core.series.Series,\n",
        "                 dialogues:  pd.core.series.Series,\n",
        "                 emotions:  pd.core.series.Series,\n",
        "                 triggers:  pd.core.series.Series,\n",
        "                 device,\n",
        "                 pad_token: str,\n",
        "                 max_num_utterances):\n",
        "        self.max_dialogue_length = dialogues.apply(len).max()\n",
        "        self.max_num_utterances = max_num_utterances\n",
        "        self.dialogues = dialogues.apply(lambda x: add_padding(x, self.max_dialogue_length, pad_token))\n",
        "        self.dialogues_ids = self.dialogues.apply(lambda x: tokenizer.convert_tokens_to_ids(x))\n",
        "        self.attention_masks = self.dialogues.apply(lambda x: [1 if token != pad_token else 0 for token in x])\n",
        "        self.speakers = speakers.apply(lambda x: add_padding(x, self.max_num_utterances, pad_value=0))\n",
        "        num_emotion_classes = len(emotions[0][0])\n",
        "        self.emotions = emotions.apply(lambda x: add_padding(x, self.max_num_utterances, pad_value = 0, pad_length = num_emotion_classes))\n",
        "        self.triggers = triggers.apply(lambda x: add_padding(x, self.max_num_utterances, pad_value=0))\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dialogues)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        speakers = torch.tensor(self.speakers.iloc[idx], dtype=torch.long).to(device)\n",
        "        dialogues_ids = torch.tensor(self.dialogues_ids.iloc[idx], dtype=torch.long).to(device)\n",
        "        dialogues_masks =  torch.tensor(self.attention_masks.iloc[idx], dtype=torch.long).to(device)\n",
        "        emotions = torch.tensor(self.emotions.iloc[idx], dtype=torch.float32).to(device)\n",
        "        triggers = torch.tensor(self.triggers.iloc[idx], dtype=torch.float32).to(device)\n",
        "        return  speakers, dialogues_ids, dialogues_masks, emotions, triggers"
      ],
      "metadata": {
        "id": "qrxDlf7pxa4d"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader(df: pd.core.frame.DataFrame, device, tokenizer, max_num_utterances, batch_size) -> torch.utils.data.dataloader.DataLoader :\n",
        "    dataset =  CustomDataset(speakers = df['speakers'],\n",
        "                                dialogues = df['dialogues'],\n",
        "                                emotions = df['emotions'],\n",
        "                                triggers = df['triggers'],\n",
        "                                device = device,\n",
        "                                pad_token = tokenizer.pad_token,\n",
        "                                max_num_utterances = max_num_utterances)\n",
        "    return DataLoader(dataset, batch_size = batch_size, shuffle = True)"
      ],
      "metadata": {
        "id": "1RfNKM1VqIHD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AbstractModel(ABC, torch.nn.Module):\n",
        "   def __init__(self, num_emotions, max_num_utterances, device):\n",
        "        super(AbstractModel, self).__init__()\n",
        "        self.num_emotions = num_emotions\n",
        "        self.max_num_utterances =max_num_utterances\n",
        "        self.device = device\n",
        "\n",
        "   @abstractmethod\n",
        "   def forward(self, token_type_ids, input_ids, attention_mask, emotions, triggers):\n",
        "        pass"
      ],
      "metadata": {
        "id": "hHWN8RzDX24O"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AbstractBERTModel( AbstractModel):\n",
        "    def __init__(self, model_card, tokenizer, num_emotions, max_num_utterances, device, freeze_embedding_layer, gru_hidden_size = None):\n",
        "        super(AbstractBERTModel, self).__init__(num_emotions, max_num_utterances, device)\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        # Load pre-trained BERT model and tokenizer\n",
        "        self.bert_model = BertModel.from_pretrained(model_card).to(device)\n",
        "\n",
        "        if freeze_embedding_layer:\n",
        "            self.bert_model.embeddings.requires_grad_(False)\n",
        "\n",
        "        self.representation_length = self.bert_model.config.hidden_size\n",
        "\n",
        "        self.emotion_classifier = nn.Sequential(\n",
        "            nn.Linear(self.representation_length, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, self.num_emotions)\n",
        "        )\n",
        "        self.gru_hidden_size  = gru_hidden_size\n",
        "        self.trigger_prediction = self._create_trigger_module()\n",
        "\n",
        "\n",
        "    @abstractmethod\n",
        "    def _create_trigger_module(self):\n",
        "        pass\n",
        "\n",
        "    def bert_forward(self, input_ids, attention_mask):\n",
        "        bert_output_1 = self.bert_model(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
        "        # Extract [SEP] token representations\n",
        "        sep_indices = (input_ids == self.tokenizer.sep_token_id).nonzero()\n",
        "        batch_size = input_ids.shape[0]\n",
        "        sep_representations = torch.zeros((batch_size, self.max_num_utterances, self.representation_length)).to(self.device)\n",
        "        dialogue_masks = torch.zeros((batch_size, self.max_num_utterances)).to(self.device)\n",
        "        for idx in range(batch_size):\n",
        "            sep_indices_idx = sep_indices[sep_indices[:,0] == idx][:,1]\n",
        "            sep_indices_idx_range = range(len(sep_indices_idx))\n",
        "            dialogue_masks[idx, sep_indices_idx_range] = 1\n",
        "            sep_representations[idx, sep_indices_idx_range, :] = bert_output_1[idx, sep_indices_idx, :]\n",
        "        return sep_representations, dialogue_masks"
      ],
      "metadata": {
        "id": "uHg7H0nj0gMJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NON SO SE IL FATTO CHE MOLTIPLICO CON LA DIALOGUE_MASK DIA PROBLEMI PER IL BACKWARD STEP, MAGARI E' EVITABILE. ANCHE NON MOLTIPLICANDO HO LO STESSO RISULTATO."
      ],
      "metadata": {
        "id": "RhM0tjT4v57A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBERTModel(AbstractBERTModel):\n",
        "    def __init__(self, model_card, tokenizer, num_emotions, max_num_utterances, device, freeze_embedding_layer, gru_hidden_size):\n",
        "        super(CustomBERTModel, self).__init__(model_card, tokenizer, num_emotions, max_num_utterances, device, freeze_embedding_layer, gru_hidden_size)\n",
        "        self.linear_trigger = nn.Linear(self.gru_hidden_size * 2, 1)\n",
        "\n",
        "\n",
        "    def _create_trigger_module(self):\n",
        "        return nn.GRU(\n",
        "            input_size=self.representation_length + num_emotions + 1,\n",
        "            hidden_size=self.gru_hidden_size,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "    def forward(self, token_type_ids, input_ids, attention_mask, _, __):\n",
        "        sep_representations, dialogue_masks = self.bert_forward(input_ids, attention_mask)\n",
        "        emotion_predictions = (self.emotion_classifier(sep_representations) * dialogue_masks.unsqueeze(-1)).to(self.device)\n",
        "        concatenated_input = torch.cat([sep_representations, emotion_predictions, token_type_ids.unsqueeze(-1)], dim=-1).to(self.device)\n",
        "        trigger_output, _ = self.trigger_prediction(concatenated_input)\n",
        "        trigger_output_single_value = self.linear_trigger(trigger_output.to(self.device)).squeeze(-1).to(self.device)\n",
        "        trigger_output_sigmoid = (torch.sigmoid(trigger_output_single_value) * dialogue_masks).to(self.device)\n",
        "        return emotion_predictions, trigger_output_sigmoid, dialogue_masks"
      ],
      "metadata": {
        "id": "F5s3MoVW0kEJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineBERTModel(AbstractBERTModel):\n",
        "    def __init__(self, model_card, tokenizer, num_emotions, max_num_utterances, device, freeze_embedding_layer=False):\n",
        "        super(BaselineBERTModel, self).__init__(model_card, tokenizer, num_emotions, max_num_utterances, device, freeze_embedding_layer)\n",
        "\n",
        "    def _create_trigger_module(self):\n",
        "        return nn.Sequential(\n",
        "            nn.Linear(self.representation_length, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, _, input_ids, attention_mask, __, ___):\n",
        "        sep_representations, dialogue_masks = self.bert_forward(input_ids, attention_mask)\n",
        "        emotion_predictions = self.emotion_classifier(sep_representations).to(self.device)\n",
        "        trigger_output = self.trigger_prediction(sep_representations).to(self.device)\n",
        "        trigger_output = trigger_output.squeeze(dim=-1).to(self.device)\n",
        "        return emotion_predictions, trigger_output, dialogue_masks"
      ],
      "metadata": {
        "id": "AvvN6rNw01fL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NoGradClassifier(AbstractModel):\n",
        "    def __init__(self, num_emotions , max_num_utterances, device):\n",
        "        super(NoGradClassifier, self).__init__(num_emotions, max_num_utterances, device)\n",
        "\n",
        "    @abstractmethod\n",
        "    def generate_emotion_index(self):\n",
        "      pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def generate_trigger(self):\n",
        "      pass\n",
        "\n",
        "    def _populate_dialogue_masks(_, dialogue_masks, emotions):\n",
        "        for batch_idx, dialogue in enumerate(emotions):\n",
        "           for utterance_idx, token in enumerate(dialogue):\n",
        "              if np.any(token.cpu().numpy()):\n",
        "                dialogue_masks[batch_idx, utterance_idx] = 1\n",
        "              else:\n",
        "                dialogue_masks[batch_idx, utterance_idx] = 0\n",
        "\n",
        "    def forward(self, _, __, ___, emotions, triggers):\n",
        "        batch_size = emotions.shape[0]\n",
        "        dialogue_masks = torch.zeros((batch_size, self.max_num_utterances)).to(self.device)\n",
        "        self._populate_dialogue_masks(dialogue_masks, emotions)\n",
        "        emotion_pred = torch.zeros((batch_size, self.max_num_utterances, self.num_emotions)).to(self.device)\n",
        "        trigger_pred = torch.zeros((batch_size, self.max_num_utterances)).to(self.device)\n",
        "        for batch_idx, dialogue in enumerate(emotions):\n",
        "           for utterance_idx, _ in enumerate(dialogue):\n",
        "               active_index = self.generate_emotion_index()\n",
        "               one_hot_encoding = np.zeros(self.num_emotions)\n",
        "               one_hot_encoding[active_index] = 1\n",
        "               emotion_pred[batch_idx, utterance_idx, :] = torch.tensor(one_hot_encoding)\n",
        "               trigger_pred[batch_idx, utterance_idx] = self.generate_trigger()\n",
        "        emotion_pred = (emotion_pred * dialogue_masks.unsqueeze(-1)).to(self.device)\n",
        "        trigger_pred = (trigger_pred * dialogue_masks).to(self.device)\n",
        "        return emotion_pred, trigger_pred, dialogue_masks\n"
      ],
      "metadata": {
        "id": "K_Tp7ZkMJS22"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomClassifier(NoGradClassifier):\n",
        "    def __init__(self, num_emotions , max_num_utterances, device, seed):\n",
        "        super(RandomClassifier, self).__init__(num_emotions, max_num_utterances, device)\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    def generate_emotion_index(self):\n",
        "        return np.random.randint(self.num_emotions)\n",
        "\n",
        "    def generate_trigger(self):\n",
        "        return random.uniform(0, 1)"
      ],
      "metadata": {
        "id": "cE_5x6jffnAV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MajorityClassifier(NoGradClassifier):\n",
        "    def __init__(self, num_emotions , max_num_utterances,device, emotions, triggers):\n",
        "        super(MajorityClassifier, self).__init__(num_emotions, max_num_utterances, device)\n",
        "        self.majority_emotion_index = self._compute_majority_emotion_index(emotions)\n",
        "        self.majority_trigger = self._compute_majority_trigger(triggers)\n",
        "\n",
        "    def _compute_majority_emotion_index(self,emotions):\n",
        "        flattened_emotions = self._flatten(emotions)\n",
        "        flattened_emotions = torch.argmax(flattened_emotions, dim = -1)\n",
        "        return mode(flattened_emotions)\n",
        "\n",
        "    def _compute_majority_trigger(self, triggers):\n",
        "        flattened_triggers = self._flatten(triggers)\n",
        "        return mode(flattened_triggers)\n",
        "\n",
        "    def _flatten(self, data):\n",
        "        flattened_array = []\n",
        "        for dialogue in data:\n",
        "          for element in dialogue:\n",
        "            flattened_array.append(element)\n",
        "        return torch.tensor(flattened_array).to(self.device)\n",
        "\n",
        "    def generate_emotion_index(self):\n",
        "        return self.majority_emotion_index\n",
        "\n",
        "    def generate_trigger(self):\n",
        "        return self.majority_trigger"
      ],
      "metadata": {
        "id": "jGFK2R8OKvWT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_pad(batch_idx, target, predictions, dialogue_length):\n",
        "        target_nopad = target[batch_idx, :dialogue_length]\n",
        "        predictions_nopad = predictions[batch_idx, :dialogue_length]\n",
        "        return target_nopad, predictions_nopad\n",
        "\n",
        "def remove_pad_predictions(batch_idx, emotions, emotion_predictions, triggers, trigger_predictions, dialogue_mask):\n",
        "        dialogue_bool = (dialogue_mask[batch_idx] == 0)\n",
        "        dialogue_true = dialogue_bool.nonzero()\n",
        "        if len(dialogue_true) == 0:\n",
        "          dialogue_length = len(dialogue_mask[batch_idx])\n",
        "        else:\n",
        "           dialogue_length = (dialogue_mask[batch_idx] == 0).nonzero()[0][0].item()\n",
        "        emotions_nopad, emotion_pred_nopad = remove_pad(batch_idx, emotions, emotion_predictions, dialogue_length)\n",
        "        triggers_nopad, trigger_pred_nopad = remove_pad(batch_idx, triggers, trigger_predictions, dialogue_length)\n",
        "        return emotions_nopad, emotion_pred_nopad, triggers_nopad, trigger_pred_nopad\n",
        "\n",
        "def update_metric_arrays(emotions_nopad, emotion_pred_nopad, triggers_nopad, triggers_pred_nopad,\n",
        "                    emotions_flat, emotions_pred_flat, triggers_flat, triggers_pred_flat,\n",
        "                    f1_seq_emotions, f1_seq_triggers):\n",
        "        emotions_flat.extend(emotions_nopad.tolist())\n",
        "        emotions_pred_flat.extend(emotion_pred_nopad.tolist())\n",
        "        triggers_flat.extend(triggers_nopad.tolist())\n",
        "        triggers_pred_flat.extend(triggers_pred_nopad.tolist())\n",
        "        f1_seq_emotions.append(f1_score(emotions_nopad.cpu().numpy(), emotion_pred_nopad.cpu().numpy(), average = 'micro'))\n",
        "        f1_seq_triggers.append(f1_score(triggers_nopad.cpu().numpy(), triggers_pred_nopad.cpu().numpy(), average = 'micro'))\n",
        "\n",
        "def get_metric_results(flattened_emotions, flattened_emotions_pred, flattened_triggers, flattened_triggers_pred, f1_sequence_emotions, f1_sequence_triggers):\n",
        "        avg_f1_sequence_emotion = sum(f1_sequence_emotions) / len(f1_sequence_emotions)\n",
        "        avg_f1_sequence_trigger = sum(f1_sequence_triggers) / len(f1_sequence_triggers)\n",
        "        f1_flattened_emotion = f1_score(flattened_emotions, flattened_emotions_pred, average='micro')\n",
        "        f1_flattened_trigger = f1_score(flattened_triggers, flattened_triggers_pred, average='micro')\n",
        "        return avg_f1_sequence_emotion, avg_f1_sequence_trigger, f1_flattened_emotion, f1_flattened_trigger\n",
        "\n",
        "def turn_into_greedy(emotions, emotion_pred, trigger_pred):\n",
        "        return torch.argmax(emotions, dim=-1), torch.argmax(emotion_pred, dim=-1), (trigger_pred > 0.5).float()"
      ],
      "metadata": {
        "id": "W-IpvSL4DEC_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nel caso di CrossEntropyLoss, devo levare le PAD PREDICTIONS (non le voglio proprio no).\n"
      ],
      "metadata": {
        "id": "XKJemp0Zt9kp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con torch.nn.BCELoss() lui si aspetta che le mie predictions siano GIA' SIGMOIDATE (tra 0 e 1). Nel caso in cui ho pad predictions e pad targets come nel caso qua sotto, il risultato e' giustamente 0. Il problema sta nel fatto che se devo fare AVERAGE di tutti i risultati, NON MI VA BENE che nel numero di esempi col quale poi andare a dividere RISULTI anche l'esempio PADDATO (che mi abbasserebbe la media, facendo aumentare il valore del denominatore)."
      ],
      "metadata": {
        "id": "oLgXgh5sukUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTraining():\n",
        "    def __init__(self, training_loader,validation_loader,test_loader,device: str,epochs=15,seed=42):\n",
        "        self.training_loader = training_loader\n",
        "        self.validation_loader = validation_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.epochs = epochs\n",
        "        self.device = device\n",
        "        self.seed = seed\n",
        "\n",
        "    def compute_loss(self, emotion_pred, emotions, trigger_pred, triggers, dialogue_mask):\n",
        "            N = 0\n",
        "            total_emotions_loss = 0\n",
        "            total_triggers_loss = 0\n",
        "            for batch_idx in range(emotion_pred.size(0)):\n",
        "                emotions_nopad, emotion_pred_nopad, triggers_nopad, triggers_pred_nopad = remove_pad_predictions(batch_idx,emotions,emotion_pred,triggers,trigger_pred,dialogue_mask)\n",
        "                discrete_emotions = torch.argmax(emotions_nopad, dim=-1).to(self.device)\n",
        "                N = N + triggers_nopad.size(0)\n",
        "                emotions_loss = torch.nn.CrossEntropyLoss(reduction ='sum')(emotion_pred_nopad, discrete_emotions)\n",
        "                triggers_loss = torch.nn.BCELoss(reduction ='sum')(triggers_pred_nopad, triggers_nopad)\n",
        "                total_emotions_loss += emotions_loss\n",
        "                total_triggers_loss += triggers_loss\n",
        "            mean_emotions_loss = total_emotions_loss/N\n",
        "            mean_triggers_loss = total_triggers_loss/N\n",
        "            loss = mean_emotions_loss + mean_triggers_loss\n",
        "            return loss.to(self.device)\n",
        "\n",
        "    def _compute_metrics(_, emotions, emotion_pred, triggers, trigger_pred, dialogue_mask,emotions_flat, emotions_pred_flat, triggers_flat, triggers_pred_flat, f1_sequence_emotions, f1_sequence_triggers):\n",
        "            emotions, emotion_pred , trigger_pred = turn_into_greedy(emotions, emotion_pred, trigger_pred)\n",
        "            for batch_idx in range(emotion_pred.size(0)):\n",
        "                emotions_nopad, emotion_pred_nopad, triggers_nopad, triggers_pred_nopad = remove_pad_predictions(batch_idx,emotions,emotion_pred,triggers,trigger_pred,dialogue_mask)\n",
        "                update_metric_arrays(emotions_nopad, emotion_pred_nopad, triggers_nopad, triggers_pred_nopad,emotions_flat, emotions_pred_flat, triggers_flat, triggers_pred_flat,f1_sequence_emotions, f1_sequence_triggers)\n",
        "\n",
        "    def _set_loop_info(self,  loop, loss, avg_loss, avg_f1_sequence_emotion, f1_flattened_emotion, avg_f1_sequence_trigger, f1_flattened_trigger):\n",
        "            loop.set_description(f'Train set.')\n",
        "            loop.set_postfix({'loss': f'{loss.item():.5}', 'loss_average': f'{avg_loss:.5}',\n",
        "                              'f1_sequence_emotion': f'{avg_f1_sequence_emotion:.5}',\n",
        "                              'f1_flattened_emotion': f'{f1_flattened_emotion:.5}',\n",
        "                              'f1_sequence_trigger': f'{avg_f1_sequence_trigger:.5}',\n",
        "                              'f1_flattened_trigger': f'{f1_flattened_trigger:.5}',})\n",
        "\n",
        "    def train_step(self, model: nn.Module, optimizer: Optimizer):\n",
        "        total_loss = 0\n",
        "        train_step = 0\n",
        "        emotions_flat, emotions_pred_flat ,triggers_flat, triggers_pred_flat, f1_sequence_emotions, f1_sequence_triggers = [],[],[],[],[],[]\n",
        "        loop = tqdm(enumerate(self.training_loader, 0), total=len(self.training_loader))\n",
        "        for _,data in loop:\n",
        "            optimizer.zero_grad()\n",
        "            train_step += 1\n",
        "            speakers, dialogues_ids, attention_masks, emotions, triggers = data\n",
        "            emotion_pred, trigger_pred, dialogue_mask =  model(speakers, dialogues_ids, attention_masks, emotions, triggers)\n",
        "            loss = self.compute_loss(emotion_pred, emotions, trigger_pred, triggers, dialogue_mask)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            self._compute_metrics(emotions, emotion_pred, triggers, trigger_pred, dialogue_mask,emotions_flat, emotions_pred_flat ,triggers_flat, triggers_pred_flat, f1_sequence_emotions, f1_sequence_triggers)\n",
        "            avg_f1_sequence_emotion, avg_f1_sequence_trigger, f1_flattened_emotion, f1_flattened_trigger = get_metric_results(emotions_flat, emotions_pred_flat ,triggers_flat, triggers_pred_flat,f1_sequence_emotions,f1_sequence_triggers)\n",
        "            total_loss += loss.item()\n",
        "            avg_loss = total_loss / train_step\n",
        "            self._set_loop_info(loop,  loss, avg_loss, avg_f1_sequence_emotion, f1_flattened_emotion, avg_f1_sequence_trigger, f1_flattened_trigger)\n",
        "        return avg_loss, avg_f1_sequence_emotion, f1_flattened_emotion, avg_f1_sequence_trigger, f1_flattened_trigger\n",
        "\n",
        "    def _populate_history(_, history, loss, f1seq_emotion, f1flat_emotion, f1seq_trigger, f1flat_trigger):\n",
        "        history['loss'].append(loss)\n",
        "        history['f1seq_emotion'].append(f1seq_emotion)\n",
        "        history['f1flat_emotion'].append(f1flat_emotion)\n",
        "        history['f1seq_trigger'].append(f1seq_trigger)\n",
        "        history['f1flat_trigger'].append(f1flat_trigger)\n",
        "\n",
        "    def train(self, model, optimizer, patience):\n",
        "            train_history = {'loss': [], 'f1seq_emotion': [], 'f1flat_emotion': [],\n",
        "                            'f1seq_trigger': [], 'f1flat_trigger': []}\n",
        "            val_history = {'loss': [], 'f1seq_emotion': [], 'f1flat_emotion': [],\n",
        "                          'f1seq_trigger': [], 'f1flat_trigger': []}\n",
        "            best_val_loss = float('inf')\n",
        "            for epoch in range(self.epochs):\n",
        "                model.train()\n",
        "                train_loss, f1seq_emotion_train, f1flat_emotion_train, f1seq_trigger_train, f1flat_trigger_train = self.train_step(model, optimizer)\n",
        "                self._populate_history(train_history, train_loss, f1seq_emotion_train, f1flat_emotion_train, f1seq_trigger_train, f1flat_trigger_train)\n",
        "                model.eval()\n",
        "                val_loss, f1seq_emotion_val, f1flat_emotion_val, f1seq_trigger_val, f1flat_trigger_val = self.evaluate(self.validation_loader, model)\n",
        "                self._populate_history(val_history, val_loss, f1seq_emotion_val, f1flat_emotion_val, f1seq_trigger_val, f1flat_trigger_val)\n",
        "                if val_loss < best_val_loss:\n",
        "                    best_val_loss = val_loss\n",
        "                    early_stopping_counter = 0\n",
        "                else:\n",
        "                    early_stopping_counter += 1\n",
        "                # Check if training should stop\n",
        "                if early_stopping_counter >= patience:\n",
        "                    print(f'Early stopping at epoch {epoch}...')\n",
        "                    break\n",
        "            return train_history, val_history\n",
        "\n",
        "    def test(self, model):\n",
        "               avg_loss, avg_f1_sequence_emotion, f1_flattened_emotion, avg_f1_sequence_trigger, f1_flattened_trigger =  self.evaluate(self.test_loader, model)\n",
        "               return {'f1_seq_emotion':avg_f1_sequence_emotion,\n",
        "                       'f1_flat_emotion':f1_flattened_emotion,\n",
        "                       'f1_seq_trigger': avg_f1_sequence_trigger,\n",
        "                       'f1_flat_trigger':f1_flattened_trigger}\n",
        "\n",
        "    def evaluate(self, dataloader, model):\n",
        "              total_loss = 0\n",
        "              evaluate_step = 0\n",
        "              emotions_flat, emotions_pred_flat ,triggers_flat, triggers_pred_flat, f1_sequence_emotions, f1_sequence_triggers = [],[],[],[],[],[]\n",
        "              with torch.no_grad():\n",
        "                  loop = tqdm(enumerate(dataloader, 0), total=len(dataloader))\n",
        "                  for _, data in loop:\n",
        "                      evaluate_step += 1\n",
        "                      speakers, dialogues_ids, attention_masks, emotions, triggers = data\n",
        "                      emotion_pred, trigger_pred, dialogue_mask =  model(speakers, dialogues_ids, attention_masks, emotions, triggers)\n",
        "                      loss = self.compute_loss(emotion_pred, emotions, trigger_pred, triggers, dialogue_mask)\n",
        "                      self._compute_metrics(emotions, emotion_pred, triggers, trigger_pred, dialogue_mask, emotions_flat, emotions_pred_flat, triggers_flat, triggers_pred_flat, f1_sequence_emotions, f1_sequence_triggers)\n",
        "                      total_loss += loss.item()\n",
        "                  avg_loss = 0.0\n",
        "                  avg_loss = total_loss / evaluate_step\n",
        "                  avg_f1_sequence_emotion, avg_f1_sequence_trigger, f1_flattened_emotion, f1_flattened_trigger = get_metric_results(emotions_flat,emotions_pred_flat,triggers_flat,triggers_pred_flat,f1_sequence_emotions,f1_sequence_triggers)\n",
        "              return avg_loss, avg_f1_sequence_emotion, f1_flattened_emotion, avg_f1_sequence_trigger, f1_flattened_trigger"
      ],
      "metadata": {
        "id": "dBzy0aqzfMBQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_trainer(dataframe: pd.core.frame.DataFrame,\n",
        "          device: str,\n",
        "          tokenizer: transformers.models.bert.tokenization_bert.BertTokenizer,\n",
        "          max_num_utterances: int,\n",
        "          batch_size: int,\n",
        "          seed):\n",
        "    df_train, df_val, df_test = split_dataframe(dataframe, seed = seed)\n",
        "    dataloader_train = create_dataloader(df_train, device, tokenizer, max_num_utterances, batch_size)\n",
        "    dataloader_val = create_dataloader(df_val, device, tokenizer, max_num_utterances, batch_size)\n",
        "    dataloader_test = create_dataloader(df_test, device, tokenizer, max_num_utterances, batch_size)\n",
        "    trainer = CustomTraining(dataloader_train, dataloader_val, dataloader_test, device)\n",
        "    return trainer"
      ],
      "metadata": {
        "id": "Clm_mx58HdLO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed_value: int):\n",
        "    random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed(seed_value)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed_value)\n",
        "    tf.random.set_seed(seed_value)"
      ],
      "metadata": {
        "id": "v2fXDRXleAQ8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_descriptive(dictionary, source=\"\"):\n",
        "    print(f\"Metrics results in evaluating {source}\")\n",
        "    for key, value in dictionary.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "    print('')"
      ],
      "metadata": {
        "id": "yLXZohTGpWUe"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_card, do_lower_case=True)\n",
        "df = pd.read_json(dataset_path)\n",
        "emotions_onehotencoder = fit_onehotencoder(df['emotions'])\n",
        "df_standard, df_variation = build_dataframes(df, emotions_onehotencoder, tokenizer)\n",
        "num_emotions =  len(emotions_onehotencoder.classes_)\n",
        "max_num_utterances = df['utterances'].apply(len).max()\n",
        "trainer_standard = build_trainer(df_standard, device, tokenizer, max_num_utterances, batch_size, initial_seed)\n",
        "trainer_variation = build_trainer(df_variation, device, tokenizer, max_num_utterances, batch_size, initial_seed)\n",
        "majority_model = MajorityClassifier(num_emotions, max_num_utterances, device, df_standard['emotions'], df_standard['triggers']).to(device)\n",
        "random_model = RandomClassifier(num_emotions, max_num_utterances, device, seed = initial_seed).to(device)\n",
        "majority_model_metrics = trainer_standard.test(majority_model)"
      ],
      "metadata": {
        "id": "9wYjxSb_aNKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f465fca-3dd5-4b6b-ee0f-fd3c5249c88a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "<ipython-input-21-a2faa6cf7061>:21: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(flattened_array).to(self.device)\n",
            "100%|██████████| 67/67 [00:02<00:00, 23.54it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_model_metrics = trainer_standard.test(random_model)\n",
        "print_descriptive(majority_model_metrics, source= 'majority model')\n",
        "print_descriptive(random_model_metrics, source= 'random model')\n",
        "\n",
        "model_names = ['bert freezed model', 'bert unfreezed model', 'custom model']\n",
        "trainable_models_metrics = {model_names[0]: {'f1_seq_emotion': [], 'f1_flat_emotion': [],'f1_seq_trigger': [], 'f1_flat_trigger': []},\n",
        "                            model_names[1]: {'f1_seq_emotion': [], 'f1_flat_emotion': [],'f1_seq_trigger': [], 'f1_flat_trigger': []},\n",
        "                            model_names[2]: {'f1_seq_emotion': [], 'f1_flat_emotion': [],'f1_seq_trigger': [], 'f1_flat_trigger': []}}\n",
        "for seed in seeds:\n",
        "  set_seed(seed)\n",
        "  custom_model = CustomBERTModel(model_card, tokenizer, num_emotions, max_num_utterances, device,  freeze_embedding_layer = False, gru_hidden_size = 256).to(device)\n",
        "  bert_freezed_model = BaselineBERTModel(model_card, tokenizer, num_emotions, max_num_utterances, device, freeze_embedding_layer = True).to(device)\n",
        "  bert_unfreezed_model = BaselineBERTModel(model_card, tokenizer, num_emotions, max_num_utterances, device, freeze_embedding_layer = False).to(device)\n",
        "  optimizer_lambda = lambda m: optim.Adam([ param for param in m.parameters() if param.requires_grad == True], lr=0.002)\n",
        "  trainable_models = [bert_freezed_model, bert_unfreezed_model, custom_model]\n",
        "  trainers = [trainer_variation, trainer_variation, trainer_standard]\n",
        "  for idx, (model, trainer) in enumerate(zip(trainable_models, trainers)):\n",
        "    print('Training model {model}, on seed {seed_value} number {number}'.format(model = model_names[idx], seed_value = seed, number = idx))\n",
        "    train_history, val_history = trainer.train(model, optimizer_lambda(model), patience)\n",
        "    model_metrics = trainer.test(model)\n",
        "    print_descriptive(model_metrics, source=model_names[idx])\n",
        "    trainable_models_metrics[model_names[idx]]['f1_seq_emotion'].append(model_metrics['f1_seq_emotion'])\n",
        "    trainable_models_metrics[model_names[idx]]['f1_flat_emotion'].append(model_metrics['f1_flat_emotion'])\n",
        "    trainable_models_metrics[model_names[idx]]['f1_seq_trigger'].append(model_metrics['f1_seq_trigger'])\n",
        "    trainable_models_metrics[model_names[idx]]['f1_flat_trigger'].append(model_metrics['f1_flat_trigger'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjVqVjuJFMjk",
        "outputId": "602af683-b7ce-4454-be69-b4327f7af6f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 67/67 [00:02<00:00, 24.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics results in evaluating majority model\n",
            "f1_seq_emotion: 0.4190589023568229\n",
            "f1_flat_emotion: 0.43461873006668594\n",
            "f1_seq_trigger: 0.7968414874529047\n",
            "f1_flat_trigger: 0.8428530008698172\n",
            "\n",
            "Metrics results in evaluating random model\n",
            "f1_seq_emotion: 0.1462686702520086\n",
            "f1_flat_emotion: 0.14554943461873007\n",
            "f1_seq_trigger: 0.4907404844023964\n",
            "f1_flat_trigger: 0.49028703972165844\n",
            "\n",
            "Training model bert freezed model, on seed 42 number 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set.:   7%|▋         | 35/534 [00:18<04:13,  1.97it/s, loss=2.0658, loss_average=2.344, f1_sequence_emotion=0.39634, f1_flattened_emotion=0.39869, f1_sequence_trigger=0.73454, f1_flattened_trigger=0.75575]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_models_metrics"
      ],
      "metadata": {
        "id": "7RuYEZRk-RwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "METRICS COMPARISON\n"
      ],
      "metadata": {
        "id": "mqqnb_JQqSSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics(train_history, val_history, metric_names, metric_labels):\n",
        "    epochs = range(1, len(train_history['loss']) + 1)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    for train_metric, val_metric, label in zip(metric_names[::2], metric_names[1::2], metric_labels):\n",
        "        plt.plot(epochs, train_history[train_metric], label=f'Training {label}', linestyle='-', linewidth=2)\n",
        "        plt.plot(epochs, val_history[val_metric], label=f'Validation {label}', linestyle='--', linewidth=2)\n",
        "\n",
        "    plt.title('Training and Validation Metrics')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Metric Value')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "taXsC4mN6tBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trigger_metric_names = ['f1seq_trigger_train', 'f1flat_trigger_train', 'f1seq_trigger_val', 'f1flat_trigger_val']\n",
        "trigger_metric_labels = ['F1 Score - Seq Trigger', 'F1 Score - Flat Trigger']\n",
        "\n",
        "plot_metrics(train_history, val_history, trigger_metric_names, trigger_metric_labels)"
      ],
      "metadata": {
        "id": "pPnLQv9b6yew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs, train_history['loss'], label='Training Loss', linestyle='-', linewidth=2)\n",
        "plt.plot(epochs, val_history['loss'], label='Validation Loss', linestyle='--', linewidth=2)"
      ],
      "metadata": {
        "id": "R1ffu_F085FY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}