{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5r6YcIoKKpG4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
        "import transformers\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Optimizer\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from abc import ABC, abstractmethod\n",
        "import random\n",
        "from statistics import mode"
      ],
      "metadata": {
        "id": "D8DvnzD7DP0M"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mount_directory = \"/content/drive\"\n",
        "dataset_path = os.path.join(mount_directory, 'MyDrive/MELD/MELD_train_efr.json')\n",
        "model_card = 'bert-base-uncased'\n",
        "drive.mount(mount_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTPAnY4jWukx",
        "outputId": "3d0ca705-fee6-4927-d2b0-7c6765fba62f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_onehotencoder(data: pd.core.series.Series) -> LabelBinarizer:\n",
        "  onehotencoder = LabelBinarizer()\n",
        "  data_flattened = np.concatenate(data.values)\n",
        "  onehotencoder.fit(data_flattened)\n",
        "  return onehotencoder"
      ],
      "metadata": {
        "id": "ENzi7RazbZeU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sbagliato, deve esserci un tokentypeids per ogni token e deve essere riferito a uno speaker particolare\n",
        "def map_to_order_of_occurrence(data: list) -> list:\n",
        "    # When a new entry is added, its value is computed using the lambda function\n",
        "    dict_order_of_occurrence = defaultdict(lambda: len(dict_order_of_occurrence)+1)\n",
        "    order_of_occurrence = [dict_order_of_occurrence[element] for element in data]\n",
        "    return order_of_occurrence"
      ],
      "metadata": {
        "id": "Pp1Tfr8PAVU8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_none_with_zero(data: list) -> list:\n",
        "    return [0 if x is None else x for x in data]"
      ],
      "metadata": {
        "id": "Qqer3ZIOE-td"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_dialogue(dialogue_text: list, tokenizer,  speakers = None) -> list:\n",
        "    if speakers!=None:\n",
        "      tokenized_dialogue = [[speakers[idx]] + tokenizer.tokenize(utterance) + [tokenizer.sep_token] for idx, utterance in enumerate(dialogue_text)]\n",
        "    else:\n",
        "      tokenized_dialogue = [tokenizer.tokenize(utterance) + [tokenizer.sep_token] for utterance in dialogue_text]\n",
        "    tokenized_dialogue.insert(0, [tokenizer.cls_token])\n",
        "    flattened_tokens = [token for sublist in tokenized_dialogue for token in sublist]\n",
        "    return flattened_tokens"
      ],
      "metadata": {
        "id": "ktvQEsNPE618"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_padding(x: list, max_x_length: int, pad_value, pad_length = None) -> list:\n",
        "    x_length = len(x)\n",
        "    num_pad_values = max_x_length - x_length\n",
        "    if pad_length == None:\n",
        "      padded_x = x + [pad_value] * num_pad_values\n",
        "    else:\n",
        "      pad_list = [pad_value] * pad_length\n",
        "      pad_lists = np.tile(pad_list, (num_pad_values, 1))\n",
        "      padded_x = np.concatenate((x, pad_lists), axis=0)\n",
        "    return padded_x"
      ],
      "metadata": {
        "id": "oA4NVL4vOd6k"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_alternative_dialogue(utterances: pd.core.series.Series, speakers: pd.core.series.Series) -> pd.core.series.Series:\n",
        "  dialogue_column = []\n",
        "  for dialogue_index, dialogue in utterances.items():\n",
        "    dialogue_column.append(tokenize_dialogue(dialogue, tokenizer, speakers[dialogue_index]))\n",
        "  return pd.Series(dialogue_column)"
      ],
      "metadata": {
        "id": "AuDGLC_mioTI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(model_card, do_lower_case=True)"
      ],
      "metadata": {
        "id": "OwnFTPgkDuHj"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json(dataset_path)\n",
        "column_names = ['emotions', 'speakers', 'triggers', 'dialogues', 'dialogues_ids', 'attention_masks']\n",
        "df_standard = pd.DataFrame(columns = column_names)\n",
        "emotions_onehotencoder = fit_onehotencoder(df['emotions'])\n",
        "df_standard['speakers'] = df['speakers'].apply(lambda x: map_to_order_of_occurrence(x))\n",
        "df_standard['emotions'] = df['emotions'].apply(lambda x: emotions_onehotencoder.transform(x))\n",
        "df_standard['triggers'] = df['triggers'].apply(lambda x: replace_none_with_zero(x))\n",
        "df_variation = copy.deepcopy(df_standard)\n",
        "df_standard['dialogues'] = df['utterances'].apply(lambda x: tokenize_dialogue(x, tokenizer))\n",
        "df_variation['dialogues'] = build_alternative_dialogue(df['utterances'], df_standard['speakers'])"
      ],
      "metadata": {
        "id": "J91TT9rH3cSC"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_emotions =  len(emotions_onehotencoder.classes_)\n",
        "max_num_utterances = df['utterances'].apply(len).max()"
      ],
      "metadata": {
        "id": "IrCAHyo39Uk8"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_dataframe(df):\n",
        "    _folder = Path.cwd().joinpath(\"dataframes\")\n",
        "    if not _folder.exists():\n",
        "        _folder.mkdir(parents=True)\n",
        "\n",
        "    df_path = Path.joinpath(_folder, 'df_MELD_efr'+'.pkl')\n",
        "    df.to_pickle(df_path)"
      ],
      "metadata": {
        "id": "5g6CwpOlYgGN"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataframe():\n",
        "    df_path = 'dataframes/df_MELD_efr.pkl'\n",
        "    if not os.path.exists(df_path):\n",
        "        raise FileNotFoundError(\"{0} dataframe does not exist!\".format(df_path))\n",
        "\n",
        "    with open(df_path, 'rb') as file:\n",
        "        df = pickle.load(file)\n",
        "    return df"
      ],
      "metadata": {
        "id": "6mJwYXvlYlMK"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataframe(orginal_df: pd.DataFrame, seed: int):\n",
        "    train, test_validation = train_test_split(orginal_df, test_size=0.2, random_state=seed)\n",
        "    validation, test = train_test_split(test_validation, test_size=0.5, random_state=seed)\n",
        "    return train.reset_index(drop=True), validation.reset_index(drop=True), test.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "keNSPuCNqcWR"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, speakers: pd.core.series.Series,\n",
        "                 dialogues:  pd.core.series.Series,\n",
        "                 emotions:  pd.core.series.Series,\n",
        "                 triggers:  pd.core.series.Series,\n",
        "                 device,\n",
        "                 pad_token: str,\n",
        "                 max_num_utterances):\n",
        "        self.max_dialogue_length = dialogues.apply(len).max()\n",
        "        self.max_num_utterances = max_num_utterances\n",
        "        self.dialogues = dialogues.apply(lambda x: add_padding(x, self.max_dialogue_length, pad_token))\n",
        "        self.dialogues_ids = self.dialogues.apply(lambda x: tokenizer.convert_tokens_to_ids(x))\n",
        "        self.attention_masks = self.dialogues.apply(lambda x: [1 if token != pad_token else 0 for token in x])\n",
        "        self.speakers = speakers.apply(lambda x: add_padding(x, self.max_num_utterances, pad_value=0))\n",
        "        num_emotion_classes = len(emotions[0][0])\n",
        "        self.emotions = emotions.apply(lambda x: add_padding(x, self.max_num_utterances, pad_value = 0, pad_length = num_emotion_classes))\n",
        "        self.triggers = triggers.apply(lambda x: add_padding(x, self.max_num_utterances, pad_value=0))\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dialogues)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        speakers = torch.tensor(self.speakers.iloc[idx], dtype=torch.long).to(device)\n",
        "        dialogues_ids = torch.tensor(self.dialogues_ids.iloc[idx], dtype=torch.long).to(device)\n",
        "        dialogues_masks =  torch.tensor(self.attention_masks.iloc[idx], dtype=torch.long).to(device)\n",
        "        emotions = torch.tensor(self.emotions.iloc[idx], dtype=torch.float32).to(device)\n",
        "        triggers = torch.tensor(self.triggers.iloc[idx], dtype=torch.float32).to(device)\n",
        "        return  speakers, dialogues_ids, dialogues_masks, emotions, triggers"
      ],
      "metadata": {
        "id": "qrxDlf7pxa4d"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader(df: pd.core.frame.DataFrame, device, tokenizer, max_num_utterances, batch_size) -> torch.utils.data.dataloader.DataLoader :\n",
        "    dataset =  CustomDataset(speakers = df['speakers'],\n",
        "                                dialogues = df['dialogues'],\n",
        "                                emotions = df['emotions'],\n",
        "                                triggers = df['triggers'],\n",
        "                                device = device,\n",
        "                                pad_token = tokenizer.pad_token,\n",
        "                                max_num_utterances = max_num_utterances)\n",
        "    return DataLoader(dataset, batch_size = batch_size, shuffle = True)"
      ],
      "metadata": {
        "id": "1RfNKM1VqIHD"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AbstractModel(ABC, torch.nn.Module):\n",
        "   def __init__(self, num_emotions, max_num_utterances):\n",
        "        super(AbstractModel, self).__init__()\n",
        "        self.num_emotions = num_emotions\n",
        "        self.max_num_utterances =max_num_utterances\n",
        "\n",
        "   @abstractmethod\n",
        "   def forward(self, token_type_ids, input_ids, attention_mask, emotions, triggers):\n",
        "        pass"
      ],
      "metadata": {
        "id": "hHWN8RzDX24O"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AbstractBERTModel( AbstractModel):\n",
        "    def __init__(self, model_card, tokenizer, num_emotions, max_num_utterances, gru_hidden_size = None, freeze_embedding_layer=False):\n",
        "        super(AbstractBERTModel, self).__init__(num_emotions, max_num_utterances)\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        # Load pre-trained BERT model and tokenizer\n",
        "        self.bert_model = BertModel.from_pretrained(model_card).to(device)\n",
        "\n",
        "        if freeze_embedding_layer:\n",
        "            for param in self.bert_model.embeddings.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        self.representation_length = self.bert_model.config.hidden_size\n",
        "\n",
        "        self.emotion_classifier = nn.Sequential(\n",
        "            nn.Linear(self.representation_length, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, self.num_emotions),\n",
        "            nn.Softmax(dim=2)\n",
        "        )\n",
        "        self.gru_hidden_size  = gru_hidden_size\n",
        "        self.trigger_prediction = self._create_trigger_module()\n",
        "\n",
        "\n",
        "    @abstractmethod\n",
        "    def _create_trigger_module(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "    def bert_forward(self, input_ids, attention_mask):\n",
        "        bert_output_1 = self.bert_model(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
        "        # Extract [SEP] token representations\n",
        "        sep_indices = (input_ids == self.tokenizer.sep_token_id).nonzero()\n",
        "        batch_size = input_ids.shape[0]\n",
        "        sep_representations = torch.zeros((batch_size, self.max_num_utterances, self.representation_length)).to(device)\n",
        "        dialogue_masks = torch.zeros((batch_size, self.max_num_utterances))\n",
        "        for idx in range(batch_size):\n",
        "            sep_indices_idx = sep_indices[sep_indices[:,0] == idx][:,1]\n",
        "            sep_indices_idx_range = range(len(sep_indices_idx))\n",
        "            dialogue_masks[idx, sep_indices_idx_range] = 1\n",
        "            sep_representations[idx, sep_indices_idx_range, :] = bert_output_1[idx, sep_indices_idx, :]\n",
        "        return sep_representations, dialogue_masks"
      ],
      "metadata": {
        "id": "uHg7H0nj0gMJ"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBERTModel(AbstractBERTModel):\n",
        "    def __init__(self, model_card, tokenizer, num_emotions, max_num_utterances, gru_hidden_size, freeze_embedding_layer=False):\n",
        "        super(CustomBERTModel, self).__init__(model_card, tokenizer, num_emotions, max_num_utterances, gru_hidden_size, freeze_embedding_layer)\n",
        "        self.linear_trigger = nn.Linear(self.gru_hidden_size * 2, 1)\n",
        "\n",
        "\n",
        "    def _create_trigger_module(self):\n",
        "        return nn.GRU(\n",
        "            input_size=self.representation_length + num_emotions + 1,\n",
        "            hidden_size=self.gru_hidden_size,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "    def forward(self, token_type_ids, input_ids, attention_mask, _, __):\n",
        "        sep_representations, dialogue_masks = self.bert_forward(input_ids, attention_mask)\n",
        "        emotion_predictions = self.emotion_classifier(sep_representations) * dialogue_masks.unsqueeze(-1)\n",
        "        concatenated_input = torch.cat([sep_representations, emotion_predictions, token_type_ids.unsqueeze(-1)], dim=-1)\n",
        "        trigger_output, _ = self.trigger_prediction(concatenated_input)\n",
        "        trigger_output_single_value = self.linear_trigger(trigger_output).squeeze(-1)\n",
        "        trigger_output_sigmoid = torch.sigmoid(trigger_output_single_value) * dialogue_masks\n",
        "        return emotion_predictions, trigger_output_sigmoid, dialogue_masks"
      ],
      "metadata": {
        "id": "F5s3MoVW0kEJ"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineBERTModel(AbstractBERTModel):\n",
        "    def __init__(self, model_card, tokenizer, num_emotions, max_num_utterances,  freeze_embedding_layer=False):\n",
        "        super(BaselineBERTModel, self).__init__(model_card, tokenizer, num_emotions, max_num_utterances, freeze_embedding_layer)\n",
        "\n",
        "    def _create_trigger_module(self):\n",
        "        return nn.Sequential(\n",
        "            nn.Linear(self.representation_length, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, _, input_ids, attention_mask, __, ___):\n",
        "        sep_representations, dialogue_masks = self.bert_forward(input_ids, attention_mask)\n",
        "        emotion_predictions = self.emotion_classifier(sep_representations) * dialogue_masks.unsqueeze(-1)\n",
        "        trigger_output = self.trigger_prediction(sep_representations) * dialogue_masks.unsqueeze(-1)\n",
        "        trigger_output = trigger_output.squeeze(dim=-1)\n",
        "        return emotion_predictions, trigger_output, dialogue_masks"
      ],
      "metadata": {
        "id": "AvvN6rNw01fL"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NoGradClassifier(AbstractModel):\n",
        "    def __init__(self, num_emotions , max_num_utterances):\n",
        "        super(NoGradClassifier, self).__init__(num_emotions, max_num_utterances)\n",
        "\n",
        "    @abstractmethod\n",
        "    def generate_emotion_index(self):\n",
        "      pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def generate_trigger(self):\n",
        "      pass\n",
        "\n",
        "    def _populate_dialogue_masks(_, dialogue_masks, emotions):\n",
        "        for batch_idx, dialogue in enumerate(emotions):\n",
        "           for utterance_idx, token in enumerate(dialogue):\n",
        "              if np.any(token.numpy()):\n",
        "                dialogue_masks[batch_idx, utterance_idx] = 1\n",
        "              else:\n",
        "                dialogue_masks[batch_idx, utterance_idx] = 0\n",
        "\n",
        "    def forward(self, _, __, ___, emotions, triggers):\n",
        "        batch_size = emotions.shape[0]\n",
        "        dialogue_masks = torch.zeros((batch_size, self.max_num_utterances))\n",
        "        self._populate_dialogue_masks(dialogue_masks, emotions)\n",
        "        emotion_pred = torch.zeros((batch_size, self.max_num_utterances, self.num_emotions))\n",
        "        trigger_pred = torch.zeros((batch_size, self.max_num_utterances))\n",
        "        for batch_idx, dialogue in enumerate(emotions):\n",
        "           for utterance_idx, _ in enumerate(dialogue):\n",
        "               active_index = self.generate_emotion_index()\n",
        "               one_hot_encoding = np.zeros(num_emotions)\n",
        "               one_hot_encoding[active_index] = 1\n",
        "               emotion_pred[batch_idx, utterance_idx, :] = torch.tensor(one_hot_encoding)\n",
        "               trigger_pred[batch_idx, utterance_idx] = self.generate_trigger()\n",
        "        emotion_pred = emotion_pred * dialogue_masks.unsqueeze(-1)\n",
        "        trigger_pred = trigger_pred * dialogue_masks\n",
        "        return emotion_pred, trigger_pred, dialogue_masks\n"
      ],
      "metadata": {
        "id": "K_Tp7ZkMJS22"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomClassifier(NoGradClassifier):\n",
        "    def __init__(self, num_emotions , max_num_utterances, seed):\n",
        "        super(RandomClassifier, self).__init__(num_emotions, max_num_utterances)\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    def generate_emotion_index(self):\n",
        "        return np.random.randint(self.num_emotions)\n",
        "\n",
        "    def generate_trigger(self):\n",
        "        return random.uniform(0, 1)"
      ],
      "metadata": {
        "id": "cE_5x6jffnAV"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MajorityClassifier(NoGradClassifier):\n",
        "    def __init__(self, num_emotions , max_num_utterances, emotions, triggers):\n",
        "        super(MajorityClassifier, self).__init__(num_emotions, max_num_utterances)\n",
        "        self.majority_emotion_index = self._compute_majority_emotion_index(emotions)\n",
        "        self.majority_trigger = self._compute_majority_trigger(triggers)\n",
        "\n",
        "    def _compute_majority_emotion_index(self,emotions):\n",
        "        flattened_emotions = self._flatten(emotions)\n",
        "        flattened_emotions = np.argmax(flattened_emotions, axis = 1)\n",
        "        return mode(flattened_emotions)\n",
        "\n",
        "    def _compute_majority_trigger(self, triggers):\n",
        "        flattened_triggers = self._flatten(triggers)\n",
        "        return mode(flattened_triggers)\n",
        "\n",
        "    def _flatten(self, data):\n",
        "        flattened_array = []\n",
        "        for dialogue in data:\n",
        "          for element in dialogue:\n",
        "            flattened_array.append(element)\n",
        "        return flattened_array\n",
        "\n",
        "    def generate_emotion_index(self):\n",
        "        return self.majority_emotion_index\n",
        "\n",
        "    def generate_trigger(self):\n",
        "        return self.majority_trigger"
      ],
      "metadata": {
        "id": "jGFK2R8OKvWT"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(emotion_pred, emotions, trigger_pred, triggers):\n",
        "        emotion_loss = F.binary_cross_entropy_with_logits(emotion_pred, emotions)\n",
        "        trigger_loss = F.binary_cross_entropy_with_logits(trigger_pred, triggers)\n",
        "        loss = emotion_loss + trigger_loss\n",
        "        return loss\n",
        "\n",
        "def remove_pad(batch_idx, target, predictions, dialogue_length):\n",
        "        target_nopad = target[batch_idx, :dialogue_length]\n",
        "        predictions_nopad = predictions[batch_idx, :dialogue_length]\n",
        "        return target_nopad, predictions_nopad\n",
        "\n",
        "def remove_pad_predictions(batch_idx, emotions, emotion_predictions, triggers, trigger_predictions, dialogue_mask):\n",
        "        dialogue_bool = (dialogue_mask[batch_idx] == 0)\n",
        "        dialogue_true = dialogue_bool.nonzero()\n",
        "        if len(dialogue_true) == 0:\n",
        "          dialogue_length = len(dialogue_mask[batch_idx])\n",
        "        else:\n",
        "           dialogue_length = (dialogue_mask[batch_idx] == 0).nonzero()[0][0].item()\n",
        "        emotions_nopad, emotion_pred_nopad = remove_pad(batch_idx, emotions, emotion_predictions, dialogue_length)\n",
        "        triggers_nopad, trigger_pred_nopad = remove_pad(batch_idx, triggers, trigger_predictions, dialogue_length)\n",
        "        return emotions_nopad, emotion_pred_nopad, triggers_nopad, trigger_pred_nopad\n",
        "\n",
        "def update_metric_arrays(emotions_nopad, emotion_pred_nopad, triggers_nopad, triggers_pred_nopad,\n",
        "                    emotions_flat, emotions_pred_flat, triggers_flat, triggers_pred_flat,\n",
        "                    f1_seq_emotions, f1_seq_triggers):\n",
        "        emotions_flat.extend(emotions_nopad.tolist())\n",
        "        emotions_pred_flat.extend(emotion_pred_nopad.tolist())\n",
        "        triggers_flat.extend(triggers_nopad.tolist())\n",
        "        triggers_pred_flat.extend(triggers_pred_nopad.tolist())\n",
        "        f1_seq_emotions.append(f1_score(emotions_nopad, emotion_pred_nopad, average = 'micro'))\n",
        "        f1_seq_triggers.append(f1_score(triggers_nopad, triggers_pred_nopad, average = 'micro'))\n",
        "\n",
        "def get_metric_results(flattened_emotions, flattened_emotions_pred, flattened_triggers, flattened_triggers_pred, f1_sequence_emotions, f1_sequence_triggers):\n",
        "        avg_f1_sequence_emotion = sum(f1_sequence_emotions) / len(f1_sequence_emotions)\n",
        "        avg_f1_sequence_trigger = sum(f1_sequence_triggers) / len(f1_sequence_triggers)\n",
        "        f1_flattened_emotion = f1_score(flattened_emotions, flattened_emotions_pred, average='micro')\n",
        "        f1_flattened_trigger = f1_score(flattened_triggers, flattened_triggers_pred, average='micro')\n",
        "        return avg_f1_sequence_emotion, avg_f1_sequence_trigger, f1_flattened_emotion, f1_flattened_trigger\n",
        "\n",
        "def turn_into_greedy(emotions, emotion_pred, trigger_pred):\n",
        "        return torch.argmax(emotions, dim=-1), torch.argmax(emotion_pred, dim=-1), (trigger_pred > 0.5).float()"
      ],
      "metadata": {
        "id": "W-IpvSL4DEC_"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTraining():\n",
        "    def __init__(self, training_loader,validation_loader,test_loader,emotions_onehotencoder,device: str,epochs=20,seed=42):\n",
        "        self.training_loader = training_loader\n",
        "        self.validation_loader = validation_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.emotions_onehotencoder = emotions_onehotencoder\n",
        "        self.epochs = epochs\n",
        "        self.device = device\n",
        "        self.seed = seed\n",
        "\n",
        "    def _compute_metrics(_, emotions, emotion_pred, triggers, trigger_pred, dialogue_mask,emotions_flat, emotions_pred_flat, triggers_flat, triggers_pred_flat, f1_sequence_emotions, f1_sequence_triggers):\n",
        "            emotions, emotion_pred , trigger_pred = turn_into_greedy(emotions, emotion_pred, trigger_pred)\n",
        "            for batch_idx in range(emotion_pred.size(0)):\n",
        "                emotions_nopad, emotion_pred_nopad, triggers_nopad, triggers_pred_nopad = remove_pad_predictions(batch_idx,emotions,emotion_pred,triggers,trigger_pred,dialogue_mask)\n",
        "                update_metric_arrays(emotions_nopad, emotion_pred_nopad, triggers_nopad, triggers_pred_nopad,emotions_flat, emotions_pred_flat, triggers_flat, triggers_pred_flat,f1_sequence_emotions, f1_sequence_triggers)\n",
        "\n",
        "    def _set_loop_info(self,  loop, loss, avg_loss, avg_f1_sequence_emotion, f1_flattened_emotion, avg_f1_sequence_trigger, f1_flattened_trigger):\n",
        "            loop.set_description(f'Train set.')\n",
        "            loop.set_postfix({'loss': f'{loss.item():.5}', 'loss_average': f'{avg_loss:.5}',\n",
        "                              'f1_sequence_emotion': f'{avg_f1_sequence_emotion:.5}',\n",
        "                              'f1_flattened_emotion': f'{f1_flattened_emotion:.5}',\n",
        "                              'f1_sequence_trigger': f'{avg_f1_sequence_trigger:.5}',\n",
        "                              'f1_flattened_trigger': f'{f1_flattened_trigger:.5}',})\n",
        "\n",
        "    def train_step(self, model: nn.Module, optimizer: Optimizer):\n",
        "        total_loss = 0\n",
        "        train_step = 0\n",
        "        emotions_flat, emotions_pred_flat ,triggers_flat, triggers_pred_flat, f1_sequence_emotions, f1_sequence_triggers = [],[],[],[],[],[]\n",
        "        loop = tqdm(enumerate(self.training_loader, 0), total=len(self.training_loader))\n",
        "        for _,data in loop:\n",
        "            optimizer.zero_grad()\n",
        "            train_step += 1\n",
        "            speakers, dialogues_ids, dialogues_masks, emotions, triggers = data\n",
        "            emotion_pred, trigger_pred, dialogue_mask =  model(speakers, dialogues_ids, dialogues_masks, emotions, triggers)\n",
        "            loss = compute_loss(emotion_pred, emotions, trigger_pred, triggers)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            self._compute_metrics(emotions, emotion_pred, triggers, trigger_pred, dialogue_mask,emotions_flat, emotions_pred_flat ,triggers_flat, triggers_pred_flat, f1_sequence_emotions, f1_sequence_triggers)\n",
        "            avg_f1_sequence_emotion, avg_f1_sequence_trigger, f1_flattened_emotion, f1_flattened_trigger = get_metric_results(emotions_flat, emotions_pred_flat ,triggers_flat, triggers_pred_flat,f1_sequence_emotions,f1_sequence_triggers)\n",
        "            total_loss += loss.item()\n",
        "            avg_loss = total_loss / train_step\n",
        "            self._set_loop_info(loop, 'Train',  loss, avg_loss, avg_f1_sequence_emotion, f1_flattened_emotion, avg_f1_sequence_trigger, f1_flattened_trigger)\n",
        "        return avg_loss, avg_f1_sequence_emotion, f1_flattened_emotion, avg_f1_sequence_trigger, f1_flattened_trigger\n",
        "\n",
        "    def _populate_history(_, history, loss, f1seq_emotion, f1flat_emotion, f1seq_trigger, f1flat_trigger):\n",
        "        history['loss'].append(loss)\n",
        "        history['f1seq_emotion'].append(f1seq_emotion)\n",
        "        history['f1flat_emotion'].append(f1flat_emotion)\n",
        "        history['f1seq_trigger'].append(f1seq_trigger)\n",
        "        history['f1flat_trigger'].append(f1flat_trigger)\n",
        "\n",
        "    def train(self, model, optimizer, patience):\n",
        "            train_history = {'loss': [], 'f1seq_emotion': [], 'f1flat_emotion': [],\n",
        "                            'f1seq_trigger': [], 'f1flat_trigger': []}\n",
        "            val_history = {'loss': [], 'f1seq_emotion': [], 'f1flat_emotion': [],\n",
        "                          'f1seq_trigger': [], 'f1flat_trigger': []}\n",
        "            best_val_loss = float('inf')\n",
        "            for epoch in range(self.epochs):\n",
        "                model.train()\n",
        "                train_loss, f1seq_emotion_train, f1flat_emotion_train, f1seq_trigger_train, f1flat_trigger_train = self.train_step(model, optimizer)\n",
        "                self._populate_history(train_history, train_loss, f1seq_emotion_train, f1flat_emotion_train, f1seq_trigger_train, f1flat_trigger_train)\n",
        "                model.eval()\n",
        "                val_loss, f1seq_emotion_val, f1flat_emotion_val, f1seq_trigger_val, f1flat_trigger_val = self.evaluate(model, self.validation_loader)\n",
        "                self._populate_history(val_history, val_loss, f1seq_emotion_val, f1flat_emotion_val, f1seq_trigger_val, f1flat_trigger_val)\n",
        "                if val_loss < best_val_loss:\n",
        "                    best_val_loss = val_loss\n",
        "                    early_stopping_counter = 0\n",
        "                else:\n",
        "                    early_stopping_counter += 1\n",
        "                # Check if training should stop\n",
        "                if early_stopping_counter >= patience:\n",
        "                    print(f'Early stopping at epoch {epoch}...')\n",
        "                    break\n",
        "            return train_history, val_history\n",
        "\n",
        "    def test(self, model):\n",
        "              return self.evaluate(self.test_loader, model)\n",
        "\n",
        "    def evaluate(self, dataloader, model):\n",
        "              total_loss = 0\n",
        "              evaluate_step = 0\n",
        "              emotions_flat, emotions_pred_flat ,triggers_flat, triggers_pred_flat, f1_sequence_emotions, f1_sequence_triggers = [],[],[],[],[],[]\n",
        "              with torch.no_grad():\n",
        "                  loop = tqdm(enumerate(dataloader, 0), total=len(dataloader))\n",
        "                  for _, data in loop:\n",
        "                      evaluate_step += 1\n",
        "                      speakers, dialogues_ids, dialogues_masks, emotions, triggers = data\n",
        "                      emotion_pred, trigger_pred, dialogue_mask =  model(speakers, dialogues_ids, dialogues_masks, emotions, triggers)\n",
        "                      loss = compute_loss(emotion_pred, emotions, trigger_pred, triggers)\n",
        "                      self._compute_metrics(emotions, emotion_pred, triggers, trigger_pred, dialogue_mask, emotions_flat, emotions_pred_flat, triggers_flat, triggers_pred_flat, f1_sequence_emotions, f1_sequence_triggers)\n",
        "                      total_loss += loss.item()\n",
        "                  avg_loss = 0.0\n",
        "                  avg_loss = total_loss / evaluate_step\n",
        "                  avg_f1_sequence_emotion, avg_f1_sequence_trigger, f1_flattened_emotion, f1_flattened_trigger = get_metric_results(emotions_flat,emotions_pred_flat,triggers_flat,triggers_pred_flat,f1_sequence_emotions,f1_sequence_triggers)\n",
        "              return avg_loss, avg_f1_sequence_emotion, f1_flattened_emotion, avg_f1_sequence_trigger, f1_flattened_trigger"
      ],
      "metadata": {
        "id": "dBzy0aqzfMBQ"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_trainer(dataframe: pd.core.frame.DataFrame,\n",
        "          device: str,\n",
        "          tokenizer: transformers.models.bert.tokenization_bert.BertTokenizer,\n",
        "          max_num_utterances: int,\n",
        "          batch_size: int):\n",
        "    df_train, df_val, df_test = split_dataframe(dataframe, 42)\n",
        "    dataloader_train = create_dataloader(df_train, device, tokenizer, max_num_utterances, batch_size)\n",
        "    dataloader_val = create_dataloader(df_val, device, tokenizer, max_num_utterances, batch_size)\n",
        "    dataloader_test = create_dataloader(df_test, device, tokenizer, max_num_utterances, batch_size)\n",
        "    trainer = CustomTraining(dataloader_train, dataloader_val, dataloader_test, emotions_onehotencoder, device)\n",
        "    return trainer"
      ],
      "metadata": {
        "id": "Clm_mx58HdLO"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "batch_size = 8\n",
        "custom_model = CustomBERTModel(model_card, tokenizer, num_emotions, max_num_utterances, gru_hidden_size = 256)\n",
        "bert_freezed_model = BaselineBERTModel(model_card, tokenizer, num_emotions, max_num_utterances, freeze_embedding_layer = True).to(device)\n",
        "bert_unfreezed_model = BaselineBERTModel(model_card, tokenizer, num_emotions, max_num_utterances, freeze_embedding_layer = False)\n",
        "\n",
        "trainer_standard = build_trainer(df_standard, device, tokenizer, max_num_utterances, batch_size)\n",
        "trainer_variation = build_trainer(df_variation, device, tokenizer, max_num_utterances, batch_size)\n",
        "optimizer_lambda = lambda m: optim.Adam(m.parameters(), lr=0.001)\n",
        "patience = 5"
      ],
      "metadata": {
        "id": "AxAfddPOM3k1"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_model = RandomClassifier(num_emotions, max_num_utterances, seed = 42)\n",
        "majority_model = MajorityClassifier(num_emotions, max_num_utterances, df_standard['emotions'], df_standard['triggers'])\n",
        "trainer_standard.test(model = majority_model)"
      ],
      "metadata": {
        "id": "697AL2-Fz7FS"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics(train_history, val_history, metric_names, metric_labels):\n",
        "    epochs = range(1, len(train_history['loss']) + 1)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    for train_metric, val_metric, label in zip(metric_names[::2], metric_names[1::2], metric_labels):\n",
        "        plt.plot(epochs, train_history[train_metric], label=f'Training {label}', linestyle='-', linewidth=2)\n",
        "        plt.plot(epochs, val_history[val_metric], label=f'Validation {label}', linestyle='--', linewidth=2)\n",
        "\n",
        "    plt.title('Training and Validation Metrics')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Metric Value')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "taXsC4mN6tBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trigger_metric_names = ['f1seq_trigger_train', 'f1flat_trigger_train', 'f1seq_trigger_val', 'f1flat_trigger_val']\n",
        "trigger_metric_labels = ['F1 Score - Seq Trigger', 'F1 Score - Flat Trigger']\n",
        "\n",
        "plot_metrics(train_history, val_history, trigger_metric_names, trigger_metric_labels)"
      ],
      "metadata": {
        "id": "pPnLQv9b6yew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs, train_history['loss'], label='Training Loss', linestyle='-', linewidth=2)\n",
        "plt.plot(epochs, val_history['loss'], label='Validation Loss', linestyle='--', linewidth=2)"
      ],
      "metadata": {
        "id": "R1ffu_F085FY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}